# This configuration can expect to reach -160 reward in 10k-20k timesteps
seeker-sacq:
    run: SACQ
    checkpoint_freq: 50
    stop:
        episode_reward_mean: 2
    config:
        # === Environment ===
        horizon: 100
        env: MultiRobot-v0
        env_config:
            headless: True
            creation_delay: 10
            reset_on_target: True

        # === Evaluation ===
        evaluation_interval: 10
        evaluation_num_episodes: 20

        # === Model ===
        use_state_preprocessor: True
        model:
            use_lstm: False
            custom_model: "sensor"

        # === Parallelism ===
        num_workers: 4
        num_gpus_per_worker: 0
        num_gpus: 0

        # === Optimization ===
        tau: 0.005
        min_iter_time_s: 60 
        compress_observations: True
        learning_starts: 10000

        optimization:
            actor_learning_rate: 0.0002
            critic_learning_rate: 0.0002
            entropy_learning_rate: 0.0002
    
