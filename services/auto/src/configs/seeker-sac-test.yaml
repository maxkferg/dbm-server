# This configuration can expect to reach -160 reward in 10k-20k timesteps
seeker-sac:
    run: SAC
    checkpoint_freq: 10
    stop:
        episode_reward_mean: 2
    config:
        # === Environment ===
        horizon: 100
        monitor: true
        env: MultiRobot-v0
        env_config:
            headless: True
            creation_delay: 1
            reset_on_target: True

        # === Evaluation ===
        evaluation_interval: 10
        evaluation_num_episodes: 10

        # === Model ===
        use_state_preprocessor: True
        model:
            use_lstm: False
            custom_model: "sensor"

        # === Model ===
        #exploration_noise_type: "gaussian"
        #exploration_gaussian_sigma: 0.06

        # === Parallelism ===
        num_workers: 6
        num_gpus_per_worker: 0

        # === Optimization ===
        tau: 0.005
        min_iter_time_s: 5
        learning_starts: 5000

        optimization:
            actor_learning_rate: 0.0003
            critic_learning_rate: 0.0003
            entropy_learning_rate: 0.0003
    